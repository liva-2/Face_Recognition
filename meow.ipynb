{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Failed to read frame from video capture\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import face_recognition\n",
    "\n",
    "# Load the face recognition model\n",
    "model = load_model('attend.h5')\n",
    "\n",
    "# Initialize empty lists to store face encodings and corresponding names\n",
    "faces = []\n",
    "names = []\n",
    "\n",
    "# Loop through each image in the 'faces' directory, resize it, and encode it using the loaded model\n",
    "for i in os.listdir('faces'):\n",
    "    # Check if the file is a valid image file\n",
    "    split_name = os.path.splitext(i)\n",
    "    if split_name[1] not in ['.jpeg', '.jpg', '.png']:\n",
    "        print(f\"Skipping invalid file: {i}\")\n",
    "        continue\n",
    "    # Load the image file\n",
    "    image = cv2.imread(os.path.join('faces', i))\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {i}\")\n",
    "        continue\n",
    "    # Resize the image to match the input size of the loaded model\n",
    "    if image.shape[:2] != (224, 224):\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "    # Expand the dimensions of the image array and normalize the pixel values\n",
    "    face_img = np.expand_dims(image, axis=0)\n",
    "    face_img = face_img / 255.0\n",
    "    # Encode the face using the loaded model\n",
    "    face_encoding = model.predict(face_img)\n",
    "    # Append the encoded face and corresponding name to the lists\n",
    "    faces.append(face_encoding)\n",
    "    names.append(split_name[0])\n",
    "\n",
    "# Create a new CSV file to record attendance\n",
    "with open('attendance.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'Time', 'Image File'])\n",
    "    \n",
    "# Initialize an empty list to keep track of recorded names\n",
    "recorded_names = []\n",
    "\n",
    "# Open the video capture device and set the frame size and encoding\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "# Check if the video capture device was successfully opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Failed to open video capture\")\n",
    "    exit(1)\n",
    "\n",
    "# Start the main loop to capture video frames and recognize faces\n",
    "while True:\n",
    "    # Read a frame from the video capture device\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read frame from video capture\")\n",
    "        break\n",
    "\n",
    "    # Convert the BGR color format to RGB format\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect face locations and encodings in the RGB frame using the face_recognition library\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    # Loop through each detected face and recognize it based on the stored encodings\n",
    "    for face_location in face_locations:\n",
    "        # Extract the coordinates of the face bounding box\n",
    "        top, right, bottom, left = face_location\n",
    "        # Extract the face image from the frame and resize it to match the input size of the loaded model\n",
    "        face_img = frame[top:bottom, left:right]\n",
    "        face_img = cv2.resize(face_img, (224, 224))\n",
    "        # Expand the dimensions of the face image array and normalize the pixel values\n",
    "        face_img = np.expand_dims(face_img, axis=0)\n",
    "        face_img = face_img / 255.0\n",
    "        # Encode the face using the loaded model\n",
    "        face_encoding = model.predict(face_img)\n",
    "        # Compute the Euclidean distance between the encoded face and each stored encoding\n",
    "        matches = []\n",
    "        for known_face_encoding in faces:\n",
    "            distance = np.linalg.norm(face_encoding - known_face_encoding)\n",
    "            # If the distance is below a certain threshold, the face is considered a match\n",
    "            if distance < 0.6:\n",
    "                matches.append(True)\n",
    "            else:\n",
    "                matches.append(False)\n",
    "        # Set the name of the recognized face to \"Unknown\" by default\n",
    "        name = \"Unknown\"\n",
    "        # If there is a match, record the attendance and save a capture of the face image\n",
    "        if True in matches:\n",
    "            index = matches.index(True)\n",
    "            name = names[index]\n",
    "            if name not in recorded_names:\n",
    "                # Generate a unique filename based on the current date and time\n",
    "                filename = f\"{name}{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\"\n",
    "                # Save the capture of the face image\n",
    "                cv2.imwrite(filename, frame)\n",
    "                # Record the attendance in the CSV file\n",
    "                with open('attendance.csv', 'a', newline='') as file:\n",
    "                    writer= csv.writer(file)\n",
    "                    writer.writerow([name, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), filename])\n",
    "                # Add the name to the list of recorded names to avoid duplicates\n",
    "                recorded_names.append(name)\n",
    "\n",
    "        # Draw a rectangle around the face bounding box and display the recognized name\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the video frame with recognized faces\n",
    "    cv2.imshow('Attendance System', frame)\n",
    "\n",
    "    # Wait for a key press and check if the 'q' or 's' key was pressed\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        # Save a capture of the current frame with a unique filename based on the current date and time\n",
    "        filename = f\"capture{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\"\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"Saved capture to {filename}\")\n",
    "\n",
    "# Release the video capture device and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
